{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426d1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "def get_page(url):\n",
    "    '''\n",
    "    A function to get a url file as lxml using BeautifulSoup\n",
    "    \n",
    "    Args:\n",
    "        url: The url address of the page to be scrapped\n",
    "    '''\n",
    "    response = rq.get(url)\n",
    "    parsed_page = bs(response.text, 'lxml')\n",
    "    return parsed_page\n",
    "\n",
    "\n",
    "def next_page(parsed_page):\n",
    "    '''\n",
    "     A function that gets the url for the next page from the current page\n",
    "     \n",
    "     Args:\n",
    "         parsed_page: A parsed HTML of a webpage.\n",
    "    '''\n",
    "    \n",
    "    pagination = parsed_page.find('div', {'class': 'pagination-wrap'})\n",
    "    if pagination.find('li', {'class': 'active'}):\n",
    "        new_url = pagination.find('a', {'id': 'page_next'})['href']\n",
    "        return new_url\n",
    "    else:\n",
    "        return\n",
    "\n",
    "\n",
    "def scrape_data(parsed_page, url, fuel_type):\n",
    "    '''\n",
    "     A function that gets the items in the given url\n",
    "     \n",
    "     Args:\n",
    "         parse_url: url for the page to scrape\n",
    "    '''\n",
    "      \n",
    "    url_list = [url, ]\n",
    "    df_list = [] # list to contain details\n",
    "    \n",
    "    \n",
    "    for i in range(1, 21):\n",
    "        try: # Exception handling to handle the error when the url returned is 'None'\n",
    "            page = get_page(url)\n",
    "            url = next_page(url)\n",
    "            if not url:\n",
    "                break\n",
    "            url_list.append(url)\n",
    "\n",
    "        except:\n",
    "            print(f'End of file. No URL returned!!!')  \n",
    "\n",
    "    \n",
    "    # iterate though products in the page to check if vehicle uses diesel\n",
    "    for url in url_list:\n",
    "        for i in range(1, 21):\n",
    "            item_url_short = parsed_page.find('div', {'id': 'pagination_container_'+str(i)}).find('div', {'class':'product-btns'}).find_all('a', {'clas':''})[1]['href']\n",
    "            item_url_full = 'https://rv.campingworld.com'+str(item_url_short)\n",
    "            response_item = rq.get(item_url_full)\n",
    "            parse_item = bs(response_item.text, 'lxml')\n",
    "            fuel = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})[1].find('h5').text\n",
    "\n",
    "            # Get vehicle details if it meets gas type specification\n",
    "            if fuel_type == fuel:\n",
    "                vehicle_name =  parse_item.find('div', {'class':'card__title'}).find('h1', {'itemprop': 'name'}).text.split(' ', 1)[1]\n",
    "                #print(vehicle_name)\n",
    "                stock_number = parse_item.find('div', {'class':'stock-num-prod-details'}).text.split(' ')[2]\n",
    "                status = parse_item.find('div', {'class':'product-card-line'}).find('h1', {'id': '#used-or-new'}).text\n",
    "                location = parse_item.find('span', {'class':'stock-results'}).find('b').text + ', ' + list(parse_item.find('span', {'class':'stock-results'}).stripped_strings)[1]\n",
    "                fuel_type = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})[1].find('h5').text\n",
    "                sleeps = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})[3].find('h5').text\n",
    "                length = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})[2].find('h5').text[:5]\n",
    "                price_low = parse_item.find('span', {'class':'price-info low-price'}).text[1:].replace(',', '')\n",
    "                if int(price_low) > 300000:\n",
    "                    horse_power = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class': 'oneSpec clearfix'})[6].find('h5').text\n",
    "                else:\n",
    "                    horse_power = ''\n",
    "                horse_power = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})\n",
    "                #print(vehicle_name)\n",
    "\n",
    "                #append details to list of fictionaries\n",
    "                df_list.append({'vehicle_name': vehicle_name,\n",
    "                                'stock_number': int(stock_number),\n",
    "                                'status': status,\n",
    "                                'location': location,\n",
    "                                'fuel_type': fuel_type,\n",
    "                                'sleeps': int(sleeps),\n",
    "                                'length': float(length),\n",
    "                                'price_low ($)': float(price_low)})\n",
    "                \n",
    "    # transform extracted data into a dataframe\n",
    "    df = pd.DataFrame(df_list, columns = ['vehicle_name', 'stock_number', 'status', 'location','fuel_type', 'sleeps',\n",
    "                                                  'length', 'price_low ($)', 'horse_power'])\n",
    "    return df\n",
    "\n",
    "\n",
    "url = 'https://rv.campingworld.com/rvclass/motorhome-rvs'\n",
    "page = get_page(url)\n",
    "check = scrape_data(page, url, 'Diesel')\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd4cb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://rv.campingworld.com/rvclass/motorhome-rvs'\n",
    "# page = get_page(url)\n",
    "# check = scrape_data(page, url, 'Diesel')\n",
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13bbd48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id=\"pagination_container_1\"', 'id=\"pagination_container_2\"', 'id=\"pagination_container_3\"', 'id=\"pagination_container_4\"', 'id=\"pagination_container_5\"', 'id=\"pagination_container_6\"', 'id=\"pagination_container_7\"', 'id=\"pagination_container_8\"', 'id=\"pagination_container_9\"', 'id=\"pagination_container_10\"', 'id=\"pagination_container_11\"', 'id=\"pagination_container_12\"', 'id=\"pagination_container_13\"', 'id=\"pagination_container_14\"', 'id=\"pagination_container_15\"', 'id=\"pagination_container_16\"', 'id=\"pagination_container_17\"', 'id=\"pagination_container_18\"', 'id=\"pagination_container_19\"', 'id=\"pagination_container_20\"']\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "# def get_page(url):\n",
    "#     '''\n",
    "#     A function to get the next url file as lxml using BeautifulSoup\n",
    "    \n",
    "#     Args:\n",
    "#         url: The url address of the page to be scrapped\n",
    "#     '''\n",
    "#     response = rq.get(url)\n",
    "#     parse_page = bs(response.text, 'lxml')\n",
    "#     return parse_page\n",
    "\n",
    "\n",
    "# def next_page(parse_page):\n",
    "#     '''\n",
    "#      A function that gets the url for the next page\n",
    "     \n",
    "#      Args:\n",
    "#          file: A parsed HTML of a webpage.\n",
    "#     '''\n",
    "    \n",
    "#     pagination = parse_page.find('div', {'class': 'pagination-wrap'})\n",
    "#     if pagination.find('li', {'class': 'active'}):\n",
    "#         new_url = pagination.find('a', {'id': 'page_next'})['href']\n",
    "#         return new_url\n",
    "#     else:\n",
    "#         return\n",
    "\n",
    "\n",
    "def scrape_data(url, fuel_type):\n",
    "    '''\n",
    "     A function that gets the items in the given url\n",
    "     \n",
    "     Args:\n",
    "         parse_url: url for the page to scrape\n",
    "    '''\n",
    "      \n",
    "    #url_list = [url, ]\n",
    "    df_list = [] # list to contain details\n",
    "    \n",
    "\n",
    "    for i in range(1, 2):\n",
    "        page_url = url + '?page=' + str(i)  \n",
    "        response = rq.get(url)\n",
    "        parse_page = bs(response.text, 'lxml')\n",
    "        #container_frames = parse_page.find('div', {'id': 'pagination_container_' + str(i)})\n",
    "        search_body = parse_page.find('div', {'id': 'content-search__body'}) # Get the section with container frames\n",
    "        container_frames = re.findall('id=\"pagination_container_\\w+\"', str(search_body)) # List of all containers for each item on the current page\n",
    "        \n",
    "        # loop through each container item and get details\n",
    "        for container in container_frames:\n",
    "            item_url_short = parse_page.find('div', {'id': 'pagination_container_' + str(i)}).find('div', {'class':'product-btns'}).find_all('a', {'clas':''})[1]['href']\n",
    "            item_url_full = 'https://rv.campingworld.com' + str(item_url_short)\n",
    "            response_item = rq.get(item_url_full)\n",
    "            parse_item = bs(response_item.text, 'lxml')\n",
    "            fuel = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})#[1].find('h5').text\n",
    "            print(fuel)\n",
    "\n",
    "            # Get vehicle details if it meets gas type specification\n",
    "#             if fuel_type == fuel:\n",
    "#                 vehicle_name =  parse_item.find('div', {'class':'card__title'}).find('h1', {'itemprop': 'name'}).text.split(' ', 1)[1]\n",
    "#                 #print(vehicle_name)\n",
    "#                 stock_number = parse_item.find('div', {'class':'stock-num-prod-details'}).text.split(' ')[2]\n",
    "#                 status = parse_item.find('div', {'class':'product-card-line'}).find('h1', {'id': '#used-or-new'}).text\n",
    "#                 location = parse_item.find('span', {'class':'stock-results'}).find('b').text + ', ' + list(parse_item.find('span', {'class':'stock-results'}).stripped_strings)[1]\n",
    "#                 fuel_type = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})[1].find('h5').text\n",
    "#                 sleeps = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})[3].find('h5').text\n",
    "#                 length = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})[2].find('h5').text[:5]\n",
    "#                 price_low = parse_item.find('span', {'class':'price-info low-price'}).text[1:].replace(',', '')\n",
    "#                 if int(price_low) > 300000:\n",
    "#                     horse_power = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class': 'oneSpec clearfix'})[6].find('h5').text\n",
    "#                 else:\n",
    "#                     horse_power = ''\n",
    "#                 horse_power = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})\n",
    "#                 print(horse_power)\n",
    "\n",
    "#                 #append extracted data to list of dictionaries\n",
    "#                 df_list.append({'vehicle_name': vehicle_name,\n",
    "#                                 'stock_number': int(stock_number),\n",
    "#                                 'status': status,\n",
    "#                                 'location': location,\n",
    "#                                 'fuel_type': fuel_type,\n",
    "#                                 'sleeps': int(sleeps),\n",
    "#                                 'length': float(length),\n",
    "#                                 'price_low ($)': float(price_low)})\n",
    "#             else:\n",
    "#                 continue\n",
    "    \n",
    "#     # transform extracted data into a data frame\n",
    "#     df = pd.DataFrame(df_list, columns = ['vehicle_name', 'stock_number', 'status', 'location','fuel_type', 'sleeps',\n",
    "#                                           'length', 'price_low ($)', 'horse_power'])\n",
    "#     return df\n",
    "\n",
    "\n",
    "url = 'https://rv.campingworld.com/rvclass/motorhome-rvs'\n",
    "check = scrape_data(url, 'Gas')\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c45acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://rv.campingworld.com/rvclass/motorhome-rvs'\n",
    "# for i in range(1, 51):\n",
    "#     url_ = url + '?page=' + str(i)\n",
    "#     print(url_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff6126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
