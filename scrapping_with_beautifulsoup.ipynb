{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de8c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "########################################################################################################################################################################\n",
    "\n",
    "def scrape_data(url, fuel_type):\n",
    "    '''\n",
    "     A function that gets the items in the given url\n",
    "     \n",
    "     Args:\n",
    "         parse_url: url for the page to scrape\n",
    "    '''\n",
    "      \n",
    "    # list to hold extracted data\n",
    "    df_list = [] \n",
    "    \n",
    "    # Iterate through all pages (20 pages)\n",
    "    for i in range(1, 21): \n",
    "        page_url = url + '?page=' + str(i)  \n",
    "        response = rq.get(page_url)\n",
    "        parse_page = bs(response.text, 'lxml')\n",
    "        search_body = parse_page.find('div', {'id': 'content-search__body'}) # Get the section with container frames\n",
    "        container_frames = re.findall('id=\"pagination_container_\\w+\"', str(search_body)) # regular expression to find all item containers\n",
    "        \n",
    "        # loop through each container item and get required details\n",
    "        for i in range(1, len(container_frames) + 1, 1):\n",
    "            item_url_short = parse_page.find('div', {'id': 'pagination_container_'+str(i)}).find('div', {'class':'product-btns'}).find_all('a', {'clas':''})[1]['href']\n",
    "            item_url_full = 'https://rv.campingworld.com' + str(item_url_short) # url to item details\n",
    "            response_item = rq.get(item_url_full)\n",
    "            parse_item = bs(response_item.text, 'lxml')\n",
    "            tab_content = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'}) # Get tab container with specifications\n",
    "            specifications_1 = [spec.find('h4').text for spec in tab_content] # list cont\n",
    "            specifications_2 = [spec.find('h5').text for spec in tab_content] # list containing specifications of each item\n",
    "            specifications = dict(zip(specifications_1, specifications_2))\n",
    "            \n",
    "            # Get vehicle details if it meets gas type specification\n",
    "            # Exception handling to skip items with missing fuel type in their specifications\n",
    "            try:\n",
    "                if fuel_type == specifications['FUEL TYPE']:\n",
    "                    vehicle_name =  parse_item.find('div', {'class':'card__title'}).find('h1', {'itemprop': 'name'}).text.split(' ', 1)[1]\n",
    "                    stock_number = parse_item.find('div', {'class':'stock-num-prod-details'}).text.split(' ')[2]\n",
    "                    status = parse_item.find('div', {'class':'product-card-line'}).find('h1', {'id': '#used-or-new'}).text\n",
    "                    location = parse_item.find('span', {'class':'stock-results'}).find('b').text + ', ' + list(parse_item.find('span', {'class':'stock-results'}).stripped_strings)[1]\n",
    "                    price_low = parse_item.find('span', {'class':'price-info low-price'}).text[1:].replace(',', '')\n",
    "                    if int(price_low) > 300000:\n",
    "                        horse_power = specifications['HORSEPOWER']\n",
    "                    else:\n",
    "                        horse_power = ''\n",
    "                    fuel = fuel_type\n",
    "                    sleeps = specifications['SLEEPS']\n",
    "                    length = specifications['LENGTH'][:5]\n",
    "\n",
    "                    #append extracted data to list of dictionaries\n",
    "                    df_list.append({'vehicle_name': vehicle_name,\n",
    "                                    'stock_number': stock_number,\n",
    "                                    'status': status,\n",
    "                                    'location': location,\n",
    "                                    'fuel_type': fuel_type,\n",
    "                                    'sleeps': int(sleeps),\n",
    "                                    'length': float(length),\n",
    "                                    'price_low ($)': float(price_low)})\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # transform extracted data into a data frame\n",
    "    df = pd.DataFrame(df_list, columns = ['vehicle_name', 'stock_number', 'status', 'location','fuel_type', 'sleeps',\n",
    "                                          'length', 'price_low ($)', 'horse_power'])\n",
    "    \n",
    "    # drop duplicates from the data set if exists\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    \n",
    "    # save dataframe as csv\n",
    "    df.to_csv(fuel_type + '_RV_Motors.csv', index = False) \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# inputs\n",
    "# url = 'https://rv.campingworld.com/rvclass/motorhome-rvs'\n",
    "# fuel_type = Diesel\n",
    "\n",
    "url = str(input('Enter url: '))\n",
    "fuel_type = str(input('Enter fuel type: '))\n",
    "\n",
    "# Run program\n",
    "scrape_data(url, fuel_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065303f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
