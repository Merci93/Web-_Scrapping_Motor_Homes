{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd97560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n",
      "End of file. No URL returned!!!\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "def get_page(url):\n",
    "    '''\n",
    "    A function to get a url file as lxml using BeautifulSoup\n",
    "    \n",
    "    Args:\n",
    "        url: The url address of the page to be scrapped\n",
    "    '''\n",
    "    response = rq.get(url)\n",
    "    parsed_page = bs(response.text, 'lxml')\n",
    "    return parsed_page\n",
    "\n",
    "\n",
    "def next_page(parsed_page):\n",
    "    '''\n",
    "     A function that gets the url for the next page from the current page\n",
    "     \n",
    "     Args:\n",
    "         parsed_page: A parsed HTML of a webpage.\n",
    "    '''\n",
    "    \n",
    "    pagination = parsed_page.find('div', {'class': 'pagination-wrap'})\n",
    "    if pagination.find('li', {'class': 'active'}):\n",
    "        new_url = pagination.find('a', {'id': 'page_next'})['href']\n",
    "        return new_url\n",
    "    else:\n",
    "        return\n",
    "\n",
    "\n",
    "def scrape_data(parsed_page, url, fuel_type):\n",
    "    '''\n",
    "     A function that gets the items in the given url\n",
    "     \n",
    "     Args:\n",
    "         parse_url: url for the page to scrape\n",
    "    '''\n",
    "      \n",
    "    url_list = [url, ]\n",
    "    df_list = [] # list to contain details\n",
    "    \n",
    "    \n",
    "    for i in range(1, 21):\n",
    "        try: # Exception handling to handle the error when the url returned is 'None'\n",
    "            page = get_page(url)\n",
    "            url = next_page(url)\n",
    "            if not url:\n",
    "                break\n",
    "            url_list.append(url)\n",
    "\n",
    "        except:\n",
    "            print(f'End of file. No URL returned!!!')  \n",
    "\n",
    "    \n",
    "    # iterate though products in the page to check if vehicle uses diesel\n",
    "    for url in url_list:\n",
    "        for i in range(1, 21):\n",
    "            item_url_short = parsed_page.find('div', {'id': 'pagination_container_'+str(i)}).find('div', {'class':'product-btns'}).find_all('a', {'clas':''})[1]['href']\n",
    "            item_url_full = 'https://rv.campingworld.com'+str(item_url_short)\n",
    "            response_item = rq.get(item_url_full)\n",
    "            parse_item = bs(response_item.text, 'lxml')\n",
    "            fuel = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})[1].find('h5').text\n",
    "\n",
    "            # Get vehicle details if it meets gas type specification\n",
    "            if fuel_type == fuel:\n",
    "                vehicle_name =  parse_item.find('div', {'class':'card__title'}).find('h1', {'itemprop': 'name'}).text.split(' ', 1)[1]\n",
    "                #print(vehicle_name)\n",
    "                stock_number = parse_item.find('div', {'class':'stock-num-prod-details'}).text.split(' ')[2]\n",
    "                status = parse_item.find('div', {'class':'product-card-line'}).find('h1', {'id': '#used-or-new'}).text\n",
    "                location = parse_item.find('span', {'class':'stock-results'}).find('b').text + ', ' + list(parse_item.find('span', {'class':'stock-results'}).stripped_strings)[1]\n",
    "                fuel_type = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})[1].find('h5').text\n",
    "                sleeps = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})[3].find('h5').text\n",
    "                length = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})[2].find('h5').text[:5]\n",
    "                price_low = parse_item.find('span', {'class':'price-info low-price'}).text[1:].replace(',', '')\n",
    "                if int(price_low) > 300000:\n",
    "                    horse_power = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class': 'oneSpec clearfix'})[6].find('h5').text\n",
    "                else:\n",
    "                    horse_power = ''\n",
    "                horse_power = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'})\n",
    "                #print(vehicle_name)\n",
    "\n",
    "                #append details to list of fictionaries\n",
    "                df_list.append({'vehicle_name': vehicle_name,\n",
    "                                'stock_number': int(stock_number),\n",
    "                                'status': status,\n",
    "                                'location': location,\n",
    "                                'fuel_type': fuel_type,\n",
    "                                'sleeps': int(sleeps),\n",
    "                                'length': float(length),\n",
    "                                'price_low ($)': float(price_low)})\n",
    "                \n",
    "    # transform extracted data into a dataframe\n",
    "    df = pd.DataFrame(df_list, columns = ['vehicle_name', 'stock_number', 'status', 'location','fuel_type', 'sleeps',\n",
    "                                                  'length', 'price_low ($)', 'horse_power'])\n",
    "    return df\n",
    "\n",
    "\n",
    "url = 'https://rv.campingworld.com/rvclass/motorhome-rvs'\n",
    "page = get_page(url)\n",
    "check = scrape_data(page, url, 'Diesel')\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eeb813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://rv.campingworld.com/rvclass/motorhome-rvs'\n",
    "# page = get_page(url)\n",
    "# check = scrape_data(page, url, 'Diesel')\n",
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b84685e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "# def get_page(url):\n",
    "#     '''\n",
    "#     A function to get the next url file as lxml using BeautifulSoup\n",
    "    \n",
    "#     Args:\n",
    "#         url: The url address of the page to be scrapped\n",
    "#     '''\n",
    "#     response = rq.get(url)\n",
    "#     parse_page = bs(response.text, 'lxml')\n",
    "#     return parse_page\n",
    "\n",
    "\n",
    "# def next_page(parse_page):\n",
    "#     '''\n",
    "#      A function that gets the url for the next page\n",
    "     \n",
    "#      Args:\n",
    "#          file: A parsed HTML of a webpage.\n",
    "#     '''\n",
    "    \n",
    "#     pagination = parse_page.find('div', {'class': 'pagination-wrap'})\n",
    "#     if pagination.find('li', {'class': 'active'}):\n",
    "#         new_url = pagination.find('a', {'id': 'page_next'})['href']\n",
    "#         return new_url\n",
    "#     else:\n",
    "#         return\n",
    "\n",
    "\n",
    "def scrape_data(url, fuel_type):\n",
    "    '''\n",
    "     A function that gets the items in the given url\n",
    "     \n",
    "     Args:\n",
    "         parse_url: url for the page to scrape\n",
    "    '''\n",
    "      \n",
    "    #url_list = [url, ]\n",
    "    df_list = [] # list to contain details\n",
    "\n",
    "    for i in range(1, 2):\n",
    "        page_url = url + '?page=' + str(i)  \n",
    "        response = rq.get(url)\n",
    "        parse_page = bs(response.text, 'lxml')\n",
    "        search_body = parse_page.find('div', {'id': 'content-search__body'}) # Get the section with container frames\n",
    "        container_frames = re.findall('id=\"pagination_container_\\w+\"', str(search_body)) # regular expression to find all item containers\n",
    "        \n",
    "        # loop through each container item and get required details\n",
    "        for i in range(1, len(container_frames) + 1, 1):\n",
    "            item_url_short = parse_page.find('div', {'id': 'pagination_container_'+str(i)}).find('div', {'class':'product-btns'}).find_all('a', {'clas':''})[1]['href']\n",
    "            item_url_full = 'https://rv.campingworld.com' + str(item_url_short) # url to item details\n",
    "            response_item = rq.get(item_url_full)\n",
    "            parse_item = bs(response_item.text, 'lxml')\n",
    "            tab_content = parse_item.find('div', {'class':'tab-content'}).find_all('div', {'class':'oneSpec clearfix'}) # Get tab container with specifications\n",
    "            specifications_1 = [spec.find('h4').text for spec in tab_content] # list cont\n",
    "            specifications_2 = [spec.find('h5').text for spec in tab_content] # list containing specifications of each item\n",
    "            specifications = dict(zip(specifications_1, specifications_2))\n",
    "            \n",
    "            # Get vehicle details if it meets gas type specification\n",
    "            if fuel_type == specifications['FUEL TYPE']:\n",
    "                vehicle_name =  parse_item.find('div', {'class':'card__title'}).find('h1', {'itemprop': 'name'}).text.split(' ', 1)[1]\n",
    "                stock_number = parse_item.find('div', {'class':'stock-num-prod-details'}).text.split(' ')[2]\n",
    "                status = parse_item.find('div', {'class':'product-card-line'}).find('h1', {'id': '#used-or-new'}).text\n",
    "                location = parse_item.find('span', {'class':'stock-results'}).find('b').text + ', ' + list(parse_item.find('span', {'class':'stock-results'}).stripped_strings)[1]\n",
    "                price_low = parse_item.find('span', {'class':'price-info low-price'}).text[1:].replace(',', '')\n",
    "                if int(price_low) > 300000:\n",
    "                    horse_power = specifications['HORSEPOWER']\n",
    "                else:\n",
    "                    horse_power = ''\n",
    "                fuel = fuel_type\n",
    "                sleeps = specifications['SLEEPS']\n",
    "                length = specifications['LENGTH'][:5]\n",
    "                \n",
    "\n",
    "                #append extracted data to list of dictionaries\n",
    "                df_list.append({'vehicle_name': vehicle_name,\n",
    "                                'stock_number': int(stock_number),\n",
    "                                'status': status,\n",
    "                                'location': location,\n",
    "                                'fuel_type': fuel_type,\n",
    "                                'sleeps': int(sleeps),\n",
    "                                'length': float(length),\n",
    "                                'price_low ($)': float(price_low)})\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    # transform extracted data into a data frame\n",
    "    df = pd.DataFrame(df_list, columns = ['vehicle_name', 'stock_number', 'status', 'location','fuel_type', 'sleeps',\n",
    "                                          'length', 'price_low ($)', 'horse_power'])\n",
    "    return df\n",
    "\n",
    "\n",
    "url = 'https://rv.campingworld.com/rvclass/motorhome-rvs'\n",
    "check = scrape_data(url, 'Gas')\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f7a71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://rv.campingworld.com/rvclass/motorhome-rvs'\n",
    "# for i in range(1, 51):\n",
    "#     url_ = url + '?page=' + str(i)\n",
    "#     print(url_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b823f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
